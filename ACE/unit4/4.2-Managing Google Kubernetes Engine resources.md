# Managing Google Kubernetes Engine Resources

## Introduction
Google Kubernetes Engine (GKE) is a managed Kubernetes service provided by Google Cloud Platform (GCP) that simplifies the deployment, management, and scaling of containerized applications using Kubernetes. This technical note will cover various aspects of managing GKE resources, from viewing cluster inventory to working with autoscaling configurations.

## Basics
### Viewing Current Running Cluster Inventory
You can use the `kubectl` command-line tool to view the current running cluster inventory. For example, to list all the nodes in your cluster, you can use the following command:
```bash
kubectl get nodes
```

### Browsing Docker Images and Artifact Registry
Google Artifact Registry allows you to store, manage, and access container images. To browse and view Docker images in the Artifact Registry, you can use the `gcloud` command:
```bash
gcloud artifacts docker images list
```

### Working with Node Pools
Node pools are a set of nodes within a GKE cluster, each with its own configuration. You can add, edit, or remove node pools using the GCP Console or the `gcloud` CLI. For example, to add a node pool to an existing cluster:
```bash
gcloud container node-pools create [POOL_NAME] --cluster [CLUSTER_NAME] --num-nodes [NUM_NODES]
```

### Working with Pods
Pods are the smallest deployable units in Kubernetes. You can add, edit, or remove pods using Kubernetes manifests. Here's an example of creating a pod from a YAML manifest file:
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: my-container
    image: nginx
```
Apply this manifest using `kubectl apply -f [YAML_FILE]`.

### Working with Services
Kubernetes Services expose pods to the network. To add, edit, or remove services, you can use YAML manifests. Here's an example of a LoadBalancer service:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer
```
Apply this manifest using `kubectl apply -f [YAML_FILE]`.

### Working with Stateful Applications
Stateful applications often require persistent volumes and stateful sets. To manage these, you can create YAML manifests. For example, to create a StatefulSet:
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-statefulset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-container
        image: nginx
      volumes:
      - name: my-storage
        emptyDir: {}
```
Apply this manifest using `kubectl apply -f [YAML_FILE]`.

### Managing Horizontal and Vertical Autoscaling
GKE supports both horizontal and vertical autoscaling. You can configure horizontal autoscaling with the `kubectl` command, while vertical autoscaling can be configured using a VerticalPodAutoscaler. For horizontal autoscaling, you might run:
```bash
kubectl autoscale deployment [DEPLOYMENT_NAME] --cpu-percent=50 --min=1 --max=10
```

### Working with Management Interfaces
GKE provides several management interfaces, including the Google Cloud Console, Cloud Shell, Cloud SDK, and `kubectl`. These interfaces allow you to monitor and manage your GKE resources. For example, to use Cloud Shell:
```bash
gcloud cloud-shell ssh
```

## Use Cases
- GKE is ideal for deploying and managing containerized applications, microservices, and batch workloads at scale.
- It's commonly used in scenarios where high availability, reliability, and automatic scaling are critical, such as web applications and API services.

## Advantages
- Managed service: GKE takes care of the underlying infrastructure, allowing developers to focus on their applications.
- Autoscaling: GKE can automatically scale the number of nodes and pods based on workload demands.
- Integration with GCP services: Seamlessly integrate with other GCP services like Cloud Monitoring and Cloud Logging.

In summary, Google Kubernetes Engine offers a comprehensive platform for container orchestration and management, simplifying the deployment and scaling of containerized applications.

For more details, you can refer to the official [GKE documentation](https://cloud.google.com/kubernetes-engine/docs).
